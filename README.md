# CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal

[![Paper - AAAI 2026](https://img.shields.io/badge/Paper-AAAI_2026-B31B1B.svg)](https://arxiv.org/abs/XXXX.XXXXX) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Official PyTorch implementation for the AAAI 2026 paper: "CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal".

<p align="center">
  <img src="Architecture.png" width="800" alt="CAST-LUT Architecture">
</p>

## ğŸ“– Abstract

Purple flare, a diffuse chromatic aberration artifact commonly found around highlight areas, severely degrades the tone transition and color of the image. Existing traditional methods are based on hand-crafted features, which lack flexibility and rely entirely on fixed priors,
while the scarcity of paired training data critically hampers deep learning.  To address this issue, we propose a novel network built upon decoupled HSV Look-Up Tables (LUTs). The method aims to simplify color correction by adjusting the Hue (H), Saturation (S), and Value (V) components independently. This approach resolves the inherent color coupling problems in traditional methods. Our model adopts a two-stage architecture: First, a Chroma-Aware Spectral Tokenizer (CAST) converts the input image from RGB space to HSV space and independently encodes the Hue (H) and Value (V) channels into a set of semantic tokens describing the Purple flare status; second, the HSV-LUT module takes these tokens as input and dynamically generates independent correction curves (1D-LUTs) for the three channels H, S, and V. To effectively train and validate our model, we built the first large-scale purple flare dataset with diverse scenes. We also proposed new metrics and a loss function specifically designed for this task. Extensive experiments demonstrate that our model not only significantly outperforms existing methods in visual effects but also achieves state-of-the-art performance on all quantitative metrics.

## âœ¨ Key Features

* **Decoupled HSV Correction**: Operates in the HSV space to perform independent 1D-LUT adjustments, avoiding color coupling issues from RGB methods.
* **Token-Guided Adaptation**: A Chroma-Aware Spectral Tokenizer (CAST) diagnoses flare characteristics into semantic tokens, which then guide the generation of adaptive correction LUTs.
* **New Dataset & Metrics**: We introduce PFSD, the first large-scale purple flare dataset, and new metrics (PSNR-F/NF, HAE) for accurate evaluation.

## ğŸ› ï¸ Installation

1.  Clone the repository:
    ```bash
    git clone [https://github.com/your-username/CAST-LUT.git](https://github.com/your-username/CAST-LUT.git)
    cd CAST-LUT
    ```

2.  Install dependencies. We recommend using a virtual environment (e.g., conda or venv).
    ```bash
    pip install -r requirements.txt
    ```

    **`requirements.txt`:**
    ```
    torch
    torchvision
    kornia
    torchmetrics
    numpy
    pillow
    tqdm
    ```

## ğŸ—‚ï¸ Repository Structure

```
CAST-LUT/
â”‚
â”œâ”€â”€ data/                    # æ•°æ®é›†æ ¹ç›®å½•
â”‚   â”œâ”€â”€ imagenet/            # (CAST é¢„è®­ç»ƒç”¨)
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â”œâ”€â”€ train/               # (LUT è®­ç»ƒç”¨)
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ gt/
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ gt/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ input/
â”‚       â””â”€â”€ gt/
â”‚
â”œâ”€â”€ pretrained/              # å­˜æ”¾é¢„è®­ç»ƒæ¨¡å‹
â”‚   â””â”€â”€ cast_hsv_best.pth    # CAST é¢„è®­ç»ƒæƒé‡
â”‚
â”œâ”€â”€ checkpoints/             # æœ€ç»ˆæ¨¡å‹çš„æ£€æŸ¥ç‚¹
â”œâ”€â”€ eval_results/            # éªŒè¯é›†çš„å¯è§†åŒ–ç»“æœ
â”œâ”€â”€ test_results/            # æœ€ç»ˆçš„æµ‹è¯•ç»“æœ
â”‚
â”œâ”€â”€ model_HSV.py             # æ ¸å¿ƒæ¨¡å‹å®šä¹‰ (CAST, HSV_LUT_Module)
â”œâ”€â”€ castHSV_train.py         # è„šæœ¬ 1: é¢„è®­ç»ƒ CAST åˆ†è¯å™¨
â”œâ”€â”€ train_test.py            # è„šæœ¬ 2: è®­ç»ƒå’Œæµ‹è¯•å®Œæ•´çš„ CAST-LUT
â”œâ”€â”€ color_utils.py           # ç§»åŠ¨ç«¯éƒ¨ç½²
â”œâ”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                # æœ¬æ–‡ä»¶
```

## ğŸš€ Usage

The full process involves two stages: (1) Pre-training the CAST tokenizer, and (2) Training the final CAST-LUT network.

### Stage 1: Pre-training CAST

First, we pre-train the `CAST` module on a large-scale dataset (e.g., ImageNet) to learn a robust visual vocabulary.

```bash
python castHSV_train.py \
    --train_path ./data/imagenet/train \
    --val_path ./data/imagenet/val \
    --checkpoint_dir ./checkpoints_cast_hsv \
```

After training, copy the best model to the `pretrained` directory:

```bash
mkdir -p pretrained
cp checkpoints_cast_hsv/cast_hsv_best.pth pretrained/cast_hsv_best.pth
```

### Stage 2: Training and Testing CAST-LUT

This unified script handles both training and testing using sub-commands.

#### Training

The script will load the pre-trained CAST weights from `pretrained/cast_hsv_best.pth`, freeze them, and train the LUT generator.

```bash
python train_test.py train \
    --train_input_dir ./data/train/input \
    --train_gt_dir ./data/train/gt \
    --val_input_dir ./data/val/input \
    --val_gt_dir ./data/val/gt \
    --pretrained_cast_path ./pretrained/cast_hsv_best.pth \
    --checkpoint_dir ./checkpoints \
    --eval_output_dir ./eval_results \
    --epochs 100 \
    --batch_size 8 \
    --num_luts 16
```

#### Testing

This will load the `best_model.pth` from the `checkpoints` directory and run evaluation on the test set.

```bash
python train_test.py test \
    --test_input_dir ./data/test/input \
    --test_gt_dir ./data/test/gt \
    --checkpoint_dir ./checkpoints \
    --output_dir ./test_results \
```

## ğŸ“Š Results

Qualitative comparison with state-of-the-art methods on our PFSD dataset. Our method (CAST-LUT) successfully removes the purple flare while preserving natural colors and details.

<p align="center">
  <img src="comparison.png" width="800" alt="Qualitative Results">
</p>


## ğŸ“œ Citation

If you find our work useful, please consider citing our paper:

```bibtex
@inproceedings{wang2026castlut,
  title     = {{CAST-LUT}: {T}okenizer-{G}uided {HSV} {L}ook-{U}p {T}ables for {P}urple {F}lare {R}emoval},
  author    = {Wang, Pu and Sun, Shuning and Lu, Jialang and Wu, Chen and Zhang, Zhihua and Zhang, Youshan and Shan, Chenggang and Lu, Dianjie and Zhang, Guijuan and Zheng, Zhuoran},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {40},
  year      = {2026}
}
```
```bibtex
Our dataset:
@misc{PuWang0_purple_flare_dataset,
  title        = {purple_flare Dataset},
  author       = {PuWang0},
  howpublished = {\url{https://huggingface.co/datasets/PuWang0/purple_flare}},
  year         = {2024} 
}
```
## ğŸ™ Acknowledgments

This work was supported by the National Natural Science Foundation of China Project (No. 62172265) and Shandong Provincial Natural Science Foundation (ZR2025MS1025, ZR2025MS1036).
